{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "559b8163",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af544ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import networkx as nx\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import igraph as ig\n",
    "import leidenalg\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from geopy.distance import great_circle\n",
    "from pyvis.network import Network\n",
    "from shapely import wkt\n",
    "import shapely.geometry\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from networkx.algorithms.community import quality\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a6f57e",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a864461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_SHOP_PHYSICAL_BRANDS_PCT = 'RELATED_CROSS_SHOPPING_PHYSICAL_BRANDS_PCT'\n",
    "X_SHOP_DIMENSIONS = ['physical']\n",
    "X_SHOP_DIMENSIONS_ALL = ['physical']\n",
    "LOCATION_NAME = 'LOCATION_NAME'\n",
    "TOP_CATEGORY = 'TOP_CATEGORY'\n",
    "RAW_NUM_CUSTOMERS = 'RAW_NUM_CUSTOMERS'\n",
    "RAW_NUM_TRANSACTIONS = 'RAW_NUM_TRANSACTIONS'\n",
    "RAW_TOTAL_SPEND = 'RAW_TOTAL_SPEND'\n",
    "POLYGON = 'POLYGON_WKT'\n",
    "\n",
    "SPEND_PLACES_PATH = 'data/san-diego-county-places-spend.parquet' # added based on joined output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd9bf49",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfb648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = duckdb.read_parquet(SPEND_PLACES_PATH)\n",
    "df = r1.to_df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6ecbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c241883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_to_tuple(json_str: str) -> list[tuple[str, int]]:\n",
    "    if not json_str:\n",
    "        return None\n",
    "    try:\n",
    "        data_dict = json.loads(json_str)\n",
    "\n",
    "        # Handle the nested structure\n",
    "        if isinstance(data_dict, dict) and \"key_value\" in data_dict:\n",
    "            return [(item[\"key\"], item[\"value\"]) for item in data_dict[\"key_value\"]]\n",
    "\n",
    "        # If it's already a flat dict\n",
    "        elif isinstance(data_dict, dict):\n",
    "            return [(k, v) for k, v in data_dict.items()]\n",
    "\n",
    "        # If it's a list of dicts already\n",
    "        elif isinstance(data_dict, list):\n",
    "            return [(item[\"key\"], item[\"value\"]) for item in data_dict]\n",
    "\n",
    "        return None\n",
    "    except (ValueError, SyntaxError, KeyError, TypeError):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6063d6",
   "metadata": {},
   "source": [
    "## Parse Related Cross Shopping Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a02ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['parsed_physical_brands'] = df[X_SHOP_PHYSICAL_BRANDS_PCT].apply(parse_json_to_tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fc5604",
   "metadata": {},
   "source": [
    "## Set Polygon Column for Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed70535",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"GEOMETRY\"] = df['POLYGON_WKT'].apply(lambda x: wkt.loads(x) if pd.notna(x) else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638addc1",
   "metadata": {},
   "source": [
    "## Construct the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1570455",
   "metadata": {},
   "source": [
    "### Cross shopping implementation\n",
    "\n",
    "This implementation accounts for location as nodes and uses cross shopping brands as edges.\n",
    "\n",
    "Notes:\n",
    "-  First builds brand index for effeciency, such that every location_node has an associated brand. We use location name as the brand, as not all locations have associated brands from SafeGraph but attributed brand names equal to brand_name. Structure in comments. \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f22c790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize graphs\n",
    "graphs = {\n",
    "    \"physical\": nx.DiGraph()\n",
    "}\n",
    "\n",
    "df[\"brand_sets\"] = df.apply(lambda row: {\n",
    "    \"physical\":     row[\"parsed_physical_brands\"]\n",
    "}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a24974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build brand-to-locations index for faster lookup\n",
    "# builds an index like:\n",
    "# {\n",
    "#     \"physical\": {\n",
    "#         \"Target\": [\n",
    "#             \"Target (33.123, -117.456)\",\n",
    "#             \"Target (34.789, -118.123)\"\n",
    "#         ],\n",
    "#         \"Walmart\": [\n",
    "#             \"Walmart (33.456, -117.789)\"...\n",
    "\n",
    "\n",
    "def build_brand_index(graphs_dict):\n",
    "    \"\"\"Build index: brand -> list of node_ids with that brand\"\"\"\n",
    "    brand_index = {}\n",
    "    for graph_name, G in graphs_dict.items():\n",
    "        brand_index[graph_name] = defaultdict(list)\n",
    "        for node_id in G.nodes():\n",
    "            brand = G.nodes[node_id].get('brand')\n",
    "            if brand:\n",
    "                brand_index[graph_name][brand].append(node_id)\n",
    "    return brand_index\n",
    "\n",
    "# add all nodes with location name as brand\n",
    "def add_nodes(row):\n",
    "    location = row[LOCATION_NAME]\n",
    "    latitude = row[\"LATITUDE\"]\n",
    "    longitude = row[\"LONGITUDE\"]\n",
    "    node_id = f\"{location} ({latitude:.6f}, {longitude:.6f})\"\n",
    "    \n",
    "    for g in graphs.values():\n",
    "        g.add_node(\n",
    "            node_id,\n",
    "            name=location,\n",
    "            brand=location,\n",
    "            label=location,\n",
    "            category=row[TOP_CATEGORY],\n",
    "            num_customers=row[RAW_NUM_CUSTOMERS],\n",
    "            num_transactions=row[RAW_NUM_TRANSACTIONS],\n",
    "            total_spend=row[RAW_TOTAL_SPEND],\n",
    "            latitude=latitude,\n",
    "            longitude=longitude,\n",
    "            geometry_wkt=row[\"POLYGON_WKT\"],\n",
    "        )\n",
    "\n",
    "df.apply(add_nodes, axis=1)\n",
    "\n",
    "# with our graphs and nodes built, we can use the function above to build the brand index\n",
    "brand_index = build_brand_index(graphs)\n",
    "\n",
    "# now we can add edges using the brand index\n",
    "def add_cross_shopping_edges(row):\n",
    "    location_or_brand = row[LOCATION_NAME]\n",
    "    latitude = row[\"LATITUDE\"]\n",
    "    longitude = row[\"LONGITUDE\"]\n",
    "    source_node_id = f\"{location_or_brand} ({latitude:.6f}, {longitude:.6f})\"\n",
    "    \n",
    "    for graph_name, brand_list in row[\"brand_sets\"].items(): # this gets our cross shopping dimension brands\n",
    "        if not brand_list:\n",
    "            continue\n",
    "        \n",
    "        G = graphs[graph_name]\n",
    "        \n",
    "        for brand, pct in brand_list: # brand list is a list of tuples with brand name and percentage\n",
    "            weight = pct / 100\n",
    "            if weight > 0.25: # bumping this up to 25% to reduce noise\n",
    "                # we use index to find target nodes quickly, reference structure above for clarification\n",
    "                # this is a similar implementation to the original implementation we are just now \n",
    "                # mapping brand to location nodes\n",
    "\n",
    "                # this retrieves the list of location nodes that have the brand (location name eg Walmart, Starbucks)\n",
    "                # and returns a list of node ids which includes the location name and coordinates\n",
    "                target_nodes = brand_index[graph_name].get(brand, [])\n",
    "                \n",
    "                # now we iterate through the target nodes and add edges\n",
    "                for target_node_id in target_nodes:\n",
    "                    # we don't want to add an edge to itself\n",
    "                    if target_node_id != source_node_id:\n",
    "                        # if the brand already exists, we aggregate the weight\n",
    "                        # this occurs because we may have multiple location nodes for the same brand\n",
    "                        # so we take the max of the weights\n",
    "                        # conversly, we don't know the exact location of the brand, so we use the max\n",
    "\n",
    "                        # practically - this checks if \"Walmart\" is already in the graph (remember this is now our source node)\n",
    "                        # and if so, it aggregates the weight of the edge\n",
    "                        if G.has_edge(source_node_id, target_node_id):\n",
    "                            G[source_node_id][target_node_id]['weight'] = max(\n",
    "                                G[source_node_id][target_node_id].get('weight', 0), \n",
    "                                weight\n",
    "                            )\n",
    "                        else:\n",
    "                            G.add_edge(source_node_id, target_node_id, weight=weight)\n",
    "\n",
    "df.apply(add_cross_shopping_edges, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274c26b0",
   "metadata": {},
   "source": [
    "### Continue brand implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043b1e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check graph nodes and edge counts\n",
    "print('Physical: ', graphs['physical'].number_of_nodes(), graphs['physical'].number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7c7148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out isolated nodes\n",
    "for name, G in graphs.items():\n",
    "    isolated_nodes = list(nx.isolates(G))\n",
    "    G.remove_nodes_from(isolated_nodes)\n",
    "    print(f\"{name} graph after removing isolates: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7589ec10",
   "metadata": {},
   "source": [
    "## Export Graph to GEXF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f642fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the graph to a GEXF file for visualization in Gephi\n",
    "def export_graph(G: nx.DiGraph, name: str):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_file = f\"graphs/{name}_graph_{timestamp}.gexf\"\n",
    "    nx.write_gexf(G, output_file)\n",
    "\n",
    "for name, G in graphs.items():\n",
    "    export_graph(G, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8918421",
   "metadata": {},
   "source": [
    "## Notes\n",
    "Overview\n",
    "- physical graph, will use this for all downstream (provide full end point to businesses)\n",
    "- louvain is baseline, laiden is primary model\n",
    "- Goal/Eval: Top N locations to provide to business / community detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c214536",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc6aed5",
   "metadata": {},
   "source": [
    "### Global Clustering Coefficient\n",
    "\n",
    " >The global clustering coefficient (aka \"transitivity\") is based on triplets of nodes. A triplet consists of three connected nodes. A triangle therefore includes three closed triplets, one centered on each of the nodes (n.b. this means the three triplets in a triangle come from overlapping selections of nodes). The global clustering coefficient is the number of closed triplets (or 3 x triangles) over the total number of triplets (both open and closed). The first attempt to measure it was made by Luce and Perry (1949). This measure gives an indication of the clustering in the whole network (global), and can be applied to both undirected and directed networks.\n",
    "\n",
    "tldr: transitivity ranges from 0 to 1 and can be interpreted as: the probability that two nodes that share a neighbor are themselves connected.\n",
    "\n",
    " GeeksforGeeks. (2022, October 31). Clustering coefficient in graph Theory. GeeksforGeeks. https://www.geeksforgeeks.org/dsa/clustering-coefficient-graph-theory/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f5e3a7",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "Adjusted this slightly. Now utilizes an appoximate method (often yields similar results) using with node and edge increase with location based method. We will also save output to pickle/dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997863eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_global_clustering_coeff(G: nx.DiGraph):\n",
    "    \"\"\"Compute global clustering with optimization for large graphs.\"\"\"\n",
    "    UG = G.to_undirected()\n",
    "    \n",
    "    # for the physical graph, we use the approximation method, too large to compute exactly\n",
    "    if G.number_of_edges() > 500000:\n",
    "        print(f\"  Graph has {G.number_of_edges()} edges - using approximation...\")\n",
    "        # sample nodes for faster computation\n",
    "        nodes = list(UG.nodes())\n",
    "        if len(nodes) > 5000:\n",
    "            import random\n",
    "            sample_nodes = random.sample(nodes, 5000)\n",
    "            local_clust = nx.clustering(UG, nodes=sample_nodes)\n",
    "        else:\n",
    "            local_clust = nx.clustering(UG)\n",
    "        return np.mean(list(local_clust.values()))\n",
    "    else:\n",
    "        # we will exact computation for smaller graphs if relevant later\n",
    "        return nx.transitivity(UG)\n",
    "\n",
    "for name, G in graphs.items():\n",
    "    print(f\"Computing clustering for {name} graph ({G.number_of_edges()} edges)...\")\n",
    "    gcc = compute_global_clustering_coeff(G)\n",
    "    print(f\"Global Clustering Coefficient for {name} graph: {gcc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3088a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect results in a list\n",
    "results = []\n",
    "\n",
    "for name, G in graphs.items():\n",
    "    print(f\"Computing clustering for {name} graph ({G.number_of_edges()} edges)...\")\n",
    "    gcc = compute_global_clustering_coeff(G)\n",
    "    print(f\"Global Clustering Coefficient for {name} graph: {gcc}\")\n",
    "    \n",
    "    results.append({\n",
    "        'graph_name': name,\n",
    "        'clustering_coefficient': gcc,\n",
    "        'num_nodes': G.number_of_nodes(),\n",
    "        'num_edges': G.number_of_edges(),\n",
    "        'method': 'approximation' if G.number_of_edges() > 500000 else 'exact'\n",
    "    })\n",
    "\n",
    "# Create DataFrame and save\n",
    "clustering_df = pd.DataFrame(results)\n",
    "clustering_df.to_csv('clustering_results.csv', index=False)\n",
    "clustering_df.to_parquet('clustering_results.parquet', index=False)  # More efficient\n",
    "\n",
    "print(f\"\\nResults saved:\")\n",
    "print(clustering_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dcb4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_global_clustering_coeff(G: nx.DiGraph):\n",
    "#     # convert digraph to undirected graph\n",
    "#     UG = G.to_undirected()\n",
    "#     return nx.transitivity(UG)\n",
    "\n",
    "# for name, G in graphs.items():\n",
    "#     gcc = compute_global_clustering_coeff(G)\n",
    "#     print(f\"Global Clustering Coefficient for {name} graph: {gcc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393214a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_pagerank(G: nx.DiGraph):\n",
    "#     pagerank = nx.pagerank(G, alpha=0.85, weight='weight')\n",
    "#     return sorted(pagerank.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# def compute_clustering(G: nx.DiGraph):\n",
    "#     clusters = nx.clustering(G, weight='weight')\n",
    "#     return sorted(clusters.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# pagerank = compute_pagerank(graphs['physical'])\n",
    "# clusters = compute_clustering(graphs['physical'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d9c697",
   "metadata": {},
   "source": [
    "Optimized for large graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd05b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pagerank(G: nx.DiGraph):\n",
    "    \"\"\"Compute PageRank with optimization for large graphs.\"\"\"\n",
    "    if G.number_of_edges() > 500000:\n",
    "        print(f\"  Large graph: {G.number_of_edges()} edges - using optimized settings...\")\n",
    "        pagerank = nx.pagerank(G, alpha=0.85, weight='weight', \n",
    "                              max_iter=50, tol=1e-5)\n",
    "    else:\n",
    "        pagerank = nx.pagerank(G, alpha=0.85, weight='weight')\n",
    "    return sorted(pagerank.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# Use optimized versions\n",
    "print(\"Computing PageRank for physical graph...\")\n",
    "pagerank = compute_pagerank(graphs['physical'])\n",
    "print(f\"✓ PageRank complete: {len(pagerank)} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571bc3f8",
   "metadata": {},
   "source": [
    "Skip additional clustering for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f664554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_clustering(G: nx.DiGraph):\n",
    "#     \"\"\"Compute clustering with sampling for large graphs.\"\"\"\n",
    "#     if G.number_of_edges() > 500000:\n",
    "#         print(f\"  Large graph: {G.number_of_edges()} edges - sampling nodes...\")\n",
    "#         nodes = list(G.nodes())\n",
    "#         if len(nodes) > 2000:\n",
    "#             import random\n",
    "#             sample_nodes = random.sample(nodes, 2000)\n",
    "#             clusters = nx.clustering(G, nodes=sample_nodes, weight='weight')\n",
    "#         else:\n",
    "#             clusters = nx.clustering(G, weight='weight')\n",
    "#     else:\n",
    "#         clusters = nx.clustering(G, weight='weight')\n",
    "#     return sorted(clusters.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "\n",
    "# print(\"\\nComputing clustering for physical graph...\")\n",
    "# clusters = compute_clustering(graphs['physical'])\n",
    "# print(f\"✓ Clustering complete: {len(clusters)} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db70cc8",
   "metadata": {},
   "source": [
    "## Degree Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc194121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find most influential nodes using out_degree \n",
    "def plot_in_out_degree(G: nx.DiGraph, related_x_shop_type: str):\n",
    "    in_degrees = dict(G.in_degree())\n",
    "    out_degrees = dict(G.out_degree())\n",
    "\n",
    "    plt.scatter(in_degrees.values(), out_degrees.values())\n",
    "    plt.xlabel(\"In-degree\")\n",
    "    plt.ylabel(\"Out-degree\")\n",
    "    plt.title(\"In vs Out Degree Distribution ({})\".format(related_x_shop_type))\n",
    "    plt.show()\n",
    "\n",
    "plot_in_out_degree(graphs['physical'], 'physical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f197d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the top n nodes with the highest out_degree\n",
    "def top_out_degree_nodes(num_nodes: int, G: nx.DiGraph) -> list[tuple[str, int]]:\n",
    "    out_degrees = dict(G.out_degree())\n",
    "    return sorted(out_degrees.items(), key=lambda item: item[1], reverse=True)[:num_nodes]\n",
    "\n",
    "top10_out_physical = top_out_degree_nodes(10, graphs['physical'])\n",
    "\n",
    "for dimension in X_SHOP_DIMENSIONS:\n",
    "    print(f\"Top 10 out-degree nodes for {dimension} graph:\")\n",
    "    top10_out = top_out_degree_nodes(10, graphs[dimension])\n",
    "    for node, degree in top10_out:\n",
    "        print(f\"{node}: {degree}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceac484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the top n nodes with the highest in_degree\n",
    "def top_in_degree_nodes(num_nodes: int, G: nx.DiGraph) -> list[tuple[str, int]]:\n",
    "    in_degrees = dict(G.in_degree())\n",
    "    return sorted(in_degrees.items(), key=lambda item: item[1], reverse=True)[:num_nodes]\n",
    "\n",
    "for dimension in X_SHOP_DIMENSIONS:\n",
    "    print(f\"Top 10 in-degree nodes for {dimension} graph:\")\n",
    "    top10_in = top_in_degree_nodes(10, graphs[dimension])\n",
    "    for node, degree in top10_in:\n",
    "        print(f\"{node}: {degree}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90754731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of in-degrees and out-degrees\n",
    "def plot_degree_distribution(G: nx.DiGraph, related_x_shop_type: str):\n",
    "    in_degrees = [d for n, d in G.in_degree()]\n",
    "    out_degrees = [d for n, d in G.out_degree()]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(in_degrees, bins=30, color='blue', alpha=0.7, log=True)\n",
    "    plt.xlabel(\"In-degree\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"In-degree Distribution ({})\".format(related_x_shop_type))\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(out_degrees, bins=30, color='green', alpha=0.7, log=True)\n",
    "    plt.xlabel(\"Out-degree\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Out-degree Distribution ({})\".format(related_x_shop_type))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_degree_distribution(graphs['physical'], 'physical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b80ab1",
   "metadata": {},
   "source": [
    "### Degree Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494f15ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all nodes that have an incoming edge into a specific node\n",
    "def first_degree_in_neighbors(node: str, G: nx.DiGraph) -> set[str]:\n",
    "    \"\"\"\n",
    "    Return all 1st-degree neighbors that have an incoming edge into `node`.\n",
    "    \"\"\"\n",
    "    if node not in G:\n",
    "        return set()\n",
    "    return set(G.predecessors(node))\n",
    "\n",
    "def first_degree_out_neighbors(node: str, G: nx.DiGraph) -> set[str]:\n",
    "    \"\"\"\n",
    "    Return the 1st-degree neighbors that have an outgoing edge from `node`.\n",
    "    \"\"\"\n",
    "    if node not in G:\n",
    "        return set()\n",
    "    return set(G.successors(node))\n",
    "\n",
    "def second_degree_in_neighbors(node: str, G: nx.DiGraph) -> set[str]:\n",
    "    \"\"\"\n",
    "    Return the 2nd-degree neighbors that have an incoming edge into `node`.\n",
    "    Excludes the node itself and direct 1st-degree neighbors.\n",
    "    \"\"\"\n",
    "    if node not in G:\n",
    "        return set()\n",
    "    first = set(G.successors(node))\n",
    "    second = set()\n",
    "    for n in first:\n",
    "        second.update(G.successors(n))\n",
    "    second -= first\n",
    "    second.discard(node)\n",
    "    return second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af34001",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_degree_in_neighbors(\"Tilly's (32.768785, -117.147968)\", graphs['physical'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c19bd7",
   "metadata": {},
   "source": [
    "## Geo-Filters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adfe824",
   "metadata": {},
   "source": [
    "We define a function that allows us to specify a radius prior to community detection. We aim to evaluate various cross-shopping communities with a geographic filter (radius in miles). This uses the intial graph created and provides a subgraph based on this determination. We can use either a center location for broader analyis, or a specific location in our dataset.\n",
    "\n",
    "First, we define a helper function to filer the nodes based on the set radius in miles. Then, we define a function that utlizes the subgraph method from NetworkX to filter based on these filtered nodes. We also use this opportunity to return only connected brands as a parameter to further filter the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a09e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to get nodes within a radius\n",
    "def get_nodes_within_radius(G, center_node, radius_mi):\n",
    "    \"\"\"\n",
    "    Get all nodes within a given radius (in km) of a center node.\n",
    "    Uses geodesic distance for accuracy.\n",
    "    \"\"\"\n",
    "    if center_node not in G:\n",
    "        return []\n",
    "    \n",
    "    center_lat = G.nodes[center_node].get('latitude')\n",
    "    center_lon = G.nodes[center_node].get('longitude')\n",
    "    \n",
    "    if center_lat is None or center_lon is None:\n",
    "        print(f\"Warning: {center_node} does not have latitude/longitude data\")\n",
    "        return []\n",
    "    \n",
    "    center_point = (center_lat, center_lon)\n",
    "    nodes_within_radius = []\n",
    "    \n",
    "    for node in G.nodes():\n",
    "        node_lat = G.nodes[node].get('latitude')\n",
    "        node_lon = G.nodes[node].get('longitude')\n",
    "        \n",
    "        if node_lat is None or node_lon is None:\n",
    "            continue\n",
    "        \n",
    "        node_point = (node_lat, node_lon)\n",
    "        distance = great_circle(center_point, node_point).miles\n",
    "        \n",
    "        if distance <= radius_mi:\n",
    "            nodes_within_radius.append(node)\n",
    "    \n",
    "    nodes_within_radius.sort(key=lambda x: x[1])\n",
    "    return nodes_within_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d06b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_graph_by_radius(G: nx.DiGraph, center_node: str, radius_mi: float, \n",
    "                           include_connected_brands: bool = True) -> nx.DiGraph:\n",
    "    \"\"\"\n",
    "    Filter a graph to include only nodes within a specified radius of a center node.\n",
    "    Optionally includes brand nodes connected to location nodes within the radius.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G : NetworkX DiGraph\n",
    "        The original graph\n",
    "    center_node : str\n",
    "        The center node (location) to filter around\n",
    "    radius_mi : float\n",
    "        Radius in miles\n",
    "    include_connected_brands : bool, default=True\n",
    "        If True, includes brand nodes connected to location nodes within radius.\n",
    "        If False, only includes location nodes within radius.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    NetworkX DiGraph : Filtered subgraph containing only nodes within radius\n",
    "    \"\"\"\n",
    "    if center_node not in G:\n",
    "        print(f\"Warning: {center_node} not found in graph\")\n",
    "        return nx.DiGraph()\n",
    "    \n",
    "    # Get location nodes within radius (nodes with lat/lon)\n",
    "    location_nodes_within_radius = get_nodes_within_radius(G, center_node, radius_mi)\n",
    "    \n",
    "    if not location_nodes_within_radius:\n",
    "        print(f\"No nodes found within {radius_mi} miles of {center_node}\")\n",
    "        return nx.DiGraph()\n",
    "    \n",
    "    # Set of nodes to include in filtered graph\n",
    "    nodes_to_include = set(location_nodes_within_radius)\n",
    "    \n",
    "    # Optionally include brand nodes connected to location nodes within radius\n",
    "    if include_connected_brands:\n",
    "        for location in location_nodes_within_radius:\n",
    "            # Get all neighbors (brands) connected to this location\n",
    "            neighbors = list(G.successors(location)) + list(G.predecessors(location))\n",
    "            nodes_to_include.update(neighbors)\n",
    "    \n",
    "    # Create subgraph with only the selected nodes\n",
    "    filtered_graph = G.subgraph(nodes_to_include).copy()\n",
    "    \n",
    "    print(f\"Filtered graph: {filtered_graph.number_of_nodes()} nodes, \"\n",
    "          f\"{filtered_graph.number_of_edges()} edges \"\n",
    "          f\"(from {G.number_of_nodes()} nodes, {G.number_of_edges()} edges)\")\n",
    "    \n",
    "    return filtered_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab63cfe5",
   "metadata": {},
   "source": [
    "## Community Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9a8cca",
   "metadata": {},
   "source": [
    "### Louvain Communities\n",
    "\n",
    "A Louvain community is a group of nodes in a network that are more densely connected to each other than to the rest of the network, identified by the Louvain algorithm through greedy modularity maximization. The algorithm iteratively moves nodes between communities to increase modularity and aggregates communities hierarchically until no further improvement is possible, producing a partition that reveals the network’s latent structure. In the context of a business cross-shopping network, Louvain communities correspond to groups of stores that share many customers relative to the broader network, highlighting patterns of customer behavior that may not align with obvious categories (Blondel et al., 2008).\n",
    "\n",
    "Citation:\n",
    "Blondel, V. D., Guillaume, J.-L., Lambiotte, R., & Lefebvre, E. (2008). Fast unfolding of communities in large networks. Journal of Statistical Mechanics: Theory and Experiment, 2008(10), P10008. https://doi.org/10.1088/1742-5468/2008/10/P10008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba9aacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_louvain_communities(G: nx.DiGraph, weight='weight', seed=47):\n",
    "    \"\"\"Detect communities in the graph using the Louvain method.\"\"\"\n",
    "    communities = nx.community.louvain_communities(G, weight=weight, seed=seed)\n",
    "\n",
    "    return communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6febb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute Louvain communities for each graph\n",
    "louvain_communities_physical = get_louvain_communities(graphs['physical'])\n",
    "\n",
    "# size of communities in each graph\n",
    "print(len(louvain_communities_physical))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b2a69",
   "metadata": {},
   "source": [
    "### Leiden Communities\n",
    "Leiden communities are groups of nodes that are densely connected internally and sparsely connected externally, identified by the Leiden algorithm. The algorithm iteratively moves nodes between communities to maximize a quality function (e.g., modularity), refines communities to ensure internal connectivity, and aggregates communities hierarchically until no further improvement is possible. Compared to Louvain, Leiden produces more stable, internally connected, and interpretable communities, making it particularly useful for real-world networks such as cross-shopping networks where loosely connected nodes and disconnected subgroups are common (Traag et al., 2019).\n",
    "\n",
    "Traag, V. A., Waltman, L., & van Eck, N. J. (2019). From Louvain to Leiden: guaranteeing well-connected communities. Scientific Reports, 9, 5233. https://arxiv.org/abs/1810.08473"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd03938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_igraph(G: nx.DiGraph) -> tuple[ig.Graph, list]:\n",
    "    \"\"\"\n",
    "    Convert a NetworkX DiGraph to an iGraph Graph.\n",
    "    Returns the graph and a list of node IDs in the same order as iGraph vertices.\n",
    "    \"\"\"\n",
    "    ig_graph = ig.Graph.from_networkx(G)\n",
    "    \n",
    "    # Get the node ids in the same order as iGraph vertices preserves the node order\n",
    "    nx_node_ids = list(G.nodes())\n",
    "    \n",
    "    return ig_graph, nx_node_ids\n",
    "\n",
    "# Convert membership to list of sets\n",
    "def leiden_to_sets(graph, partition, nx_node_ids):\n",
    "    \"\"\"\n",
    "    Convert Leiden partition to list of sets of node IDs.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    graph : ig.Graph\n",
    "        The iGraph graph\n",
    "    partition : leidenalg.RBConfigurationVertexPartition\n",
    "        The partition object\n",
    "    nx_node_ids : list\n",
    "        List of NetworkX node IDs in the same order as iGraph vertices\n",
    "    \"\"\"\n",
    "    communities = defaultdict(set)\n",
    "    \n",
    "    # Map partition membership to NetworkX node IDs\n",
    "    for i, cid in enumerate(partition.membership):\n",
    "        node_id = nx_node_ids[i]  # Get the actual node_id from NetworkX\n",
    "        communities[cid].add(node_id)\n",
    "    \n",
    "    return list(communities.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c55bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_physical, nx_nodes_physical = convert_to_igraph(graphs['physical'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80713041",
   "metadata": {},
   "outputs": [],
   "source": [
    "leiden_communities_physical = leidenalg.find_partition(graph=ig_physical,\n",
    "                                                  partition_type=leidenalg.ModularityVertexPartition, \n",
    "                                                  weights='weight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73d4e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "leiden_set_physical = leiden_to_sets(ig_physical, leiden_communities_physical, nx_nodes_physical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fa77bb",
   "metadata": {},
   "source": [
    "### Evaluate Community Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeeefcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_community_quality(G: nx.DiGraph, communities: list[set[str]]):\n",
    "    \"\"\"Evaluate the quality of the detected communities using modularity.\"\"\"\n",
    "    Q = quality.modularity(G, communities)\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3d1d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = evaluate_community_quality(graphs['physical'], louvain_communities_physical)\n",
    "\n",
    "print(\"Evaluating Louvain Communities\")\n",
    "print(f\"Modularity Scores (physical): {mod}\")\n",
    "print()\n",
    "print(\"Evaluating Leiden Communities\")\n",
    "print(f\"Modularity Scores (physical): {leiden_communities_physical.modularity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7872bf2d",
   "metadata": {},
   "source": [
    "## Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0bc79d",
   "metadata": {},
   "source": [
    "We define a mapping function to display nodes in the graph, and optionally their associated community. This function returns a folium map object including:\n",
    "- Lines drawn between graph edges \n",
    "- Community color coding, if community assignments are provided\n",
    "- Pop ups to provide additional detail (e.g. category, total spend, customers)\n",
    "\n",
    "We can save the map file if we specify a name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e293473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_filtered_graph(G: nx.DiGraph, \n",
    "                            center_node: str = None,\n",
    "                            center_lat: float = None,\n",
    "                            center_lon: float = None,\n",
    "                            communities: list[set[str]] = None,\n",
    "                            show_edges: bool = True,\n",
    "                            show_polygons: bool = False,\n",
    "                            zoom_start: int = 12,\n",
    "                            output_file: str = None) -> folium.Map:\n",
    "    \"\"\"\n",
    "    Visualize filtered graph nodes on a folium map.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    G : NetworkX DiGraph\n",
    "        The filtered graph to visualize\n",
    "    center_node : str, optional\n",
    "        Center node name (used to center map if center_lat/lon not provided)\n",
    "    center_lat : float, optional\n",
    "        Center latitude for map\n",
    "    center_lon : float, optional\n",
    "        Center longitude for map\n",
    "    communities : list of sets, optional\n",
    "        Community assignments (for color-coding nodes)\n",
    "    df : pd.DataFrame, optional\n",
    "        Deprecated - kept for backward compatibility. Geometry now comes from node attributes.\n",
    "    show_edges : bool, default=True\n",
    "        Whether to show edges between nodes as lines\n",
    "    show_polygons : bool, default=False\n",
    "        Whether to show polygon geometries from node attributes\n",
    "    zoom_start : int, default=12\n",
    "        Initial zoom level\n",
    "    output_file : str, optional\n",
    "        Filename to save map (e.g., 'filtered_graph_map.html')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    folium.Map : The folium map object\n",
    "    \"\"\"\n",
    "    # Determine map center\n",
    "    if center_lat is not None and center_lon is not None:\n",
    "        map_center = [center_lat, center_lon]\n",
    "    elif center_node and center_node in G:\n",
    "        center_lat = G.nodes[center_node].get('latitude')\n",
    "        center_lon = G.nodes[center_node].get('longitude')\n",
    "        if center_lat and center_lon:\n",
    "            map_center = [center_lat, center_lon]\n",
    "        else:\n",
    "            # Calculate center from all nodes\n",
    "            lats = [G.nodes[n].get('latitude') for n in G.nodes() \n",
    "                   if G.nodes[n].get('latitude') is not None]\n",
    "            lons = [G.nodes[n].get('longitude') for n in G.nodes() \n",
    "                   if G.nodes[n].get('longitude') is not None]\n",
    "            map_center = [np.mean(lats), np.mean(lons)] if lats else [33.036986, -117.292447]\n",
    "    else:\n",
    "        # Calculate center from all nodes\n",
    "        lats = [G.nodes[n].get('latitude') for n in G.nodes() \n",
    "               if G.nodes[n].get('latitude') is not None]\n",
    "        lons = [G.nodes[n].get('longitude') for n in G.nodes() \n",
    "               if G.nodes[n].get('longitude') is not None]\n",
    "        map_center = [np.mean(lats), np.mean(lons)] if lats else [33.036986, -117.292447]\n",
    "    \n",
    "    # Create map\n",
    "    m = folium.Map(location=map_center, zoom_start=zoom_start)\n",
    "    \n",
    "    # Create community color mapping if communities provided\n",
    "    node_to_community = {}\n",
    "    if communities:\n",
    "        colors = plt.cm.Set3(np.linspace(0, 1, len(communities)))\n",
    "        for i, comm in enumerate(communities):\n",
    "            for node in comm:\n",
    "                node_to_community[node] = i\n",
    "    else:\n",
    "        # Default color if no communities\n",
    "        colors = None\n",
    "    \n",
    "    # Add polygons if requested (using geometry from node attributes)\n",
    "    if show_polygons:\n",
    "        # Collect nodes with geometry\n",
    "        features = []\n",
    "        for node in G.nodes():\n",
    "            geometry_wkt = G.nodes[node].get('geometry_wkt')  # Get WKT string\n",
    "            if geometry_wkt is not None:\n",
    "                try:\n",
    "                    # Convert WKT string to Shapely geometry\n",
    "                    geometry = wkt.loads(geometry_wkt)\n",
    "                    \n",
    "                    # Get node attributes for popup\n",
    "                    category = G.nodes[node].get('category', 'N/A')\n",
    "                    \n",
    "                    # Convert Shapely geometry to GeoJSON format\n",
    "                    geojson_geom = shapely.geometry.mapping(geometry)\n",
    "                    \n",
    "                    # Create GeoJSON feature\n",
    "                    feature = {\n",
    "                        \"type\": \"Feature\",\n",
    "                        \"geometry\": geojson_geom,\n",
    "                        \"properties\": {\n",
    "                            \"LOCATION_NAME\": node,\n",
    "                            \"TOP_CATEGORY\": category\n",
    "                        }\n",
    "                    }\n",
    "                    features.append(feature)\n",
    "                except Exception as e:\n",
    "                    # Skip invalid geometries\n",
    "                    continue\n",
    "        \n",
    "        if features:\n",
    "            geojson_data = {\n",
    "                \"type\": \"FeatureCollection\",\n",
    "                \"features\": features\n",
    "            }\n",
    "            \n",
    "            folium.GeoJson(\n",
    "                geojson_data,\n",
    "                style_function=lambda feature: {\n",
    "                    'fillColor': 'lightblue',\n",
    "                    'color': 'blue',\n",
    "                    'weight': 1,\n",
    "                    'fillOpacity': 0.3,\n",
    "                },\n",
    "                tooltip=folium.GeoJsonTooltip(fields=['LOCATION_NAME'], aliases=['Location:']),\n",
    "                popup=folium.GeoJsonPopup(fields=['LOCATION_NAME', 'TOP_CATEGORY'])\n",
    "            ).add_to(m)\n",
    "    \n",
    "    # Add edges as lines\n",
    "    if show_edges:\n",
    "        for u, v, data in G.edges(data=True):\n",
    "            u_lat = G.nodes[u].get('latitude')\n",
    "            u_lon = G.nodes[u].get('longitude')\n",
    "            v_lat = G.nodes[v].get('latitude')\n",
    "            v_lon = G.nodes[v].get('longitude')\n",
    "            \n",
    "            # Only draw edge if both nodes have coordinates (location nodes)\n",
    "            if (u_lat is not None and u_lon is not None and \n",
    "                v_lat is not None and v_lon is not None):\n",
    "                weight = data.get('weight', 1.0)\n",
    "                # Scale line width based on weight\n",
    "                line_width = max(1, min(5, weight * 10))\n",
    "                \n",
    "                folium.PolyLine(\n",
    "                    locations=[[u_lat, u_lon], [v_lat, v_lon]],\n",
    "                    weight=line_width,\n",
    "                    color='gray',\n",
    "                    opacity=0.05\n",
    "                ).add_to(m)\n",
    "    \n",
    "    # Add markers for location nodes (nodes with lat/lon)\n",
    "    for node in G.nodes():\n",
    "        node_lat = G.nodes[node].get('latitude')\n",
    "        node_lon = G.nodes[node].get('longitude')\n",
    "        \n",
    "        # Skip nodes without coordinates (likely brand nodes)\n",
    "        if node_lat is None or node_lon is None:\n",
    "            continue\n",
    "        \n",
    "        # Determine color based on community\n",
    "        if communities and node in node_to_community:\n",
    "            comm_id = node_to_community[node]\n",
    "            color = mcolors.rgb2hex(colors[comm_id][:3])\n",
    "            icon_color = 'white'\n",
    "        else:\n",
    "            color = 'blue'\n",
    "            icon_color = 'white'\n",
    "        \n",
    "        # Get node attributes for popup\n",
    "        category = G.nodes[node].get('category', 'N/A')\n",
    "        num_customers = G.nodes[node].get('num_customers', 'N/A')\n",
    "        total_spend = G.nodes[node].get('total_spend', 'N/A')\n",
    "        \n",
    "        # Create popup HTML\n",
    "        popup_html = f\"\"\"\n",
    "        <div style=\"font-family: Arial; width: 200px;\">\n",
    "            <h4 style=\"margin: 5px 0;\">{node}</h4>\n",
    "            <p style=\"margin: 2px 0;\"><b>Category:</b> {category}</p>\n",
    "            <p style=\"margin: 2px 0;\"><b>Customers:</b> {num_customers}</p>\n",
    "            <p style=\"margin: 2px 0;\"><b>Total Spend:</b> ${total_spend:,.2f}</p>\n",
    "        </div>\n",
    "        \"\"\" if isinstance(total_spend, (int, float)) else f\"\"\"\n",
    "        <div style=\"font-family: Arial; width: 200px;\">\n",
    "            <h4 style=\"margin: 5px 0;\">{node}</h4>\n",
    "            <p style=\"margin: 2px 0;\"><b>Category:</b> {category}</p>\n",
    "            <p style=\"margin: 2px 0;\"><b>Customers:</b> {num_customers}</p>\n",
    "            <p style=\"margin: 2px 0;\"><b>Total Spend:</b> {total_spend}</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        \n",
    "        folium.CircleMarker(\n",
    "            location=[node_lat, node_lon],\n",
    "            radius=6,\n",
    "            popup=folium.Popup(popup_html, max_width=300),\n",
    "            tooltip=node,\n",
    "            color='black',\n",
    "            fillColor=color,\n",
    "            fillOpacity=0.7,\n",
    "            weight=2\n",
    "        ).add_to(m)\n",
    "    \n",
    "    # Add center marker if center_node specified\n",
    "    if center_node and center_node in G:\n",
    "        center_lat = G.nodes[center_node].get('latitude')\n",
    "        center_lon = G.nodes[center_node].get('longitude')\n",
    "        if center_lat and center_lon:\n",
    "            folium.Marker(\n",
    "                location=[center_lat, center_lon],\n",
    "                popup=f\"Center: {center_node}\",\n",
    "                tooltip=f\"Center: {center_node}\",\n",
    "                icon=folium.Icon(color='red', icon='star', prefix='fa')\n",
    "            ).add_to(m)\n",
    "    \n",
    "    # Save map if filename provided\n",
    "    if output_file:\n",
    "        m.save(output_file)\n",
    "        print(f\"Map saved to {output_file}\")\n",
    "    \n",
    "    return m\n",
    "\n",
    "\n",
    "# Convenience function for filtered graph visualization\n",
    "def visualize_filtered_communities(filtered_G: nx.DiGraph, \n",
    "                                   communities: list[set[str]],\n",
    "                                   center_node: str = None,\n",
    "                                   output_file: str = None) -> folium.Map:\n",
    "    \"\"\"\n",
    "    Visualize filtered graph with community assignments.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    filtered_G : NetworkX DiGraph\n",
    "        The filtered graph\n",
    "    communities : list of sets\n",
    "        Community assignments\n",
    "    center_node : str, optional\n",
    "        Center node name\n",
    "    df : pd.DataFrame, optional\n",
    "        Deprecated - geometry now comes from node attributes\n",
    "    output_file : str, optional\n",
    "        Output filename\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    folium.Map : The folium map\n",
    "    \"\"\"\n",
    "    return visualize_filtered_graph(\n",
    "        G=filtered_G,\n",
    "        center_node=center_node,\n",
    "        communities=communities,\n",
    "        show_edges=True,\n",
    "        show_polygons=False,\n",
    "        output_file=output_file\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d0ca51",
   "metadata": {},
   "source": [
    "### Show example map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfadbf0",
   "metadata": {},
   "source": [
    "Below shows a complete example of capt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0595413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_node = \"McDonald's (32.981937, -117.076287)\"\n",
    "radius_miles = 2.0\n",
    "graph_type = 'physical' \n",
    "\n",
    "filtered_graph = filter_graph_by_radius(\n",
    "    graphs[graph_type], \n",
    "    center_node=center_node, \n",
    "    radius_mi=radius_miles,\n",
    "    include_connected_brands=False # can be set to false to exclude brand nodes\n",
    ")\n",
    "\n",
    "print(f\"Filtered graph: {filtered_graph.number_of_nodes()} nodes, {filtered_graph.number_of_edges()} edges\")\n",
    "\n",
    "# run community detection on the filtered graph\n",
    "# we first re-remove isolated nodes first in subgraph\n",
    "isolated = list(nx.isolates(filtered_graph))\n",
    "filtered_graph.remove_nodes_from(isolated)\n",
    "print(f\"After removing isolates: {filtered_graph.number_of_nodes()} nodes, {filtered_graph.number_of_edges()} edges\")\n",
    "\n",
    "# run louvain community detection for now. We can use leiden later.\n",
    "# we can also use global community detection from before, but this is faster- more stable for api calls \n",
    "communities = get_louvain_communities(filtered_graph)\n",
    "\n",
    "print(f\"\\nFound {len(communities)} communities\")\n",
    "for i, comm in enumerate(communities):\n",
    "    print(f\"  Community {i+1}: {len(comm)} nodes\")\n",
    "\n",
    "# visualize the filtered graph with communities\n",
    "map_viz = visualize_filtered_graph(\n",
    "    G=filtered_graph,\n",
    "    center_node=center_node,\n",
    "    communities=communities,\n",
    "    show_edges=True,\n",
    "    show_polygons=True, \n",
    "    zoom_start=14, \n",
    "    output_file='mcdonalds_2mile_communities.html' # change as needed\n",
    ")\n",
    "\n",
    "# Display the map\n",
    "map_viz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
